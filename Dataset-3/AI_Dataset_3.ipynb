{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kPMYMEWZBbcG"
      },
      "outputs": [],
      "source": [
        "!unzip -q /Dataset-3.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oYP6mZa7DqHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199c1cfe-bd44-49e3-acc6-1b8b01cd2c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install libraries (if not already available)\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "87SWdW9jIWK-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyEWCUgAIfid",
        "outputId": "72ec3d3a-34b6-4f8f-f7a3-45e16dc7ab99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['apple', 'baked potato', 'burger', 'coffee', 'curry', 'donut', 'durian', 'egg ballado', 'french fries', 'fried chicken', 'fried rice', 'gado gado', 'grapes', 'hot dog', 'ice cream', 'kebab', 'meatballs', 'mineral water', 'noodle', 'nuts', 'omelette', 'orange', 'pizza', 'porridge', 'prawn crackers', 'rendang', 'sandwich', 'satay', 'soto', 'taco']\n",
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Define data directories\n",
        "data_dir = \"/content/food_datasets\"\n",
        "train_dir = f\"{data_dir}/train\"\n",
        "valid_dir = f\"{data_dir}/valid\"\n",
        "test_dir = f\"{data_dir}/test\"\n",
        "\n",
        "# Define data transformations\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the datasets\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
        "    'valid': datasets.ImageFolder(valid_dir, transform=data_transforms['valid']),\n",
        "    'test': datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
        "}\n",
        "\n",
        "# Define dataloaders\n",
        "batch_size = 32\n",
        "dataloaders = {\n",
        "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
        "    'valid': DataLoader(image_datasets['valid'], batch_size=batch_size, shuffle=False),\n",
        "    'test': DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=False)\n",
        "}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXRW4NFtI-pk",
        "outputId": "c9ecce61-484f-4b82-fb56-ca440b020e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 88.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 47.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Function to load and modify models\n",
        "def initialize_model(model_name, num_classes, feature_extract=True):\n",
        "    if model_name == \"vgg16\":\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        if feature_extract:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    elif model_name == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        if feature_extract:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# Initialize models\n",
        "num_classes = len(class_names)\n",
        "vgg16 = initialize_model(\"vgg16\", num_classes)\n",
        "resnet18 = initialize_model(\"resnet18\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J5RpneSsJpqb"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Deep copy the model if it has improved\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print('Best validation Acc: {:4f}'.format(best_acc))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnVjG8XsJyHr",
        "outputId": "2052a7c2-9653-4d21-e5fa-d8406a1cba94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VGG16\n",
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 1.4449 Acc: 0.5983\n",
            "valid Loss: 0.8030 Acc: 0.7878\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.9597 Acc: 0.7162\n",
            "valid Loss: 0.7224 Acc: 0.7977\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.8877 Acc: 0.7310\n",
            "valid Loss: 0.6461 Acc: 0.8236\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.8685 Acc: 0.7381\n",
            "valid Loss: 0.6454 Acc: 0.8205\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.8462 Acc: 0.7399\n",
            "valid Loss: 0.6062 Acc: 0.8274\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.8021 Acc: 0.7558\n",
            "valid Loss: 0.6081 Acc: 0.8335\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.8003 Acc: 0.7570\n",
            "valid Loss: 0.5896 Acc: 0.8342\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.7864 Acc: 0.7563\n",
            "valid Loss: 0.5870 Acc: 0.8281\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.7711 Acc: 0.7545\n",
            "valid Loss: 0.6060 Acc: 0.8213\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.7724 Acc: 0.7620\n",
            "valid Loss: 0.5957 Acc: 0.8365\n",
            "Best validation Acc: 0.836502\n",
            "\n",
            "Training ResNet18\n",
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 2.1557 Acc: 0.4636\n",
            "valid Loss: 1.3683 Acc: 0.6875\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 1.3387 Acc: 0.6671\n",
            "valid Loss: 1.0003 Acc: 0.7529\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 1.1078 Acc: 0.7098\n",
            "valid Loss: 0.8665 Acc: 0.7711\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.9924 Acc: 0.7299\n",
            "valid Loss: 0.7860 Acc: 0.7871\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.9354 Acc: 0.7486\n",
            "valid Loss: 0.7490 Acc: 0.7939\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.8817 Acc: 0.7566\n",
            "valid Loss: 0.7218 Acc: 0.8008\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.8448 Acc: 0.7654\n",
            "valid Loss: 0.6759 Acc: 0.8099\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.8156 Acc: 0.7689\n",
            "valid Loss: 0.6664 Acc: 0.8129\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.8006 Acc: 0.7716\n",
            "valid Loss: 0.6598 Acc: 0.8030\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.7682 Acc: 0.7817\n",
            "valid Loss: 0.6308 Acc: 0.8137\n",
            "Best validation Acc: 0.813688\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train VGG16\n",
        "print(\"Training VGG16\")\n",
        "optimizer_vgg = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "vgg16 = train_model(vgg16, criterion, optimizer_vgg, num_epochs=10)\n",
        "\n",
        "# Train ResNet18\n",
        "print(\"\\nTraining ResNet18\")\n",
        "optimizer_resnet = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
        "resnet18 = train_model(resnet18, criterion, optimizer_resnet, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            _, top5_preds = torch.topk(outputs, 5, 1, largest=True, sorted=True)\n",
        "\n",
        "            correct += torch.sum(preds == labels)\n",
        "            total += labels.size(0)\n",
        "            top5_correct += torch.sum(torch.eq(top5_preds, labels.view(-1,1)).any(dim=1))\n",
        "\n",
        "    accuracy = correct.double() / total\n",
        "    top5_accuracy = top5_correct.double() / total\n",
        "    print(f'Accuracy: {accuracy:.4f}, Top-5 Accuracy: {top5_accuracy:.4f}')\n",
        "\n",
        "# Evaluate VGG16\n",
        "print(\"\\nEvaluating VGG16 on test set\")\n",
        "evaluate_model(vgg16)\n",
        "\n",
        "# Evaluate ResNet18\n",
        "print(\"\\nEvaluating ResNet18 on test set\")\n",
        "evaluate_model(resnet18)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0W7j27UkUKh",
        "outputId": "22572f7a-792e-4768-9f0a-9ee1e2871000"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating VGG16 on test set\n",
            "Accuracy: 0.8260, Top-5 Accuracy: 0.9782\n",
            "\n",
            "Evaluating ResNet18 on test set\n",
            "Accuracy: 0.8329, Top-5 Accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def print_classification_report(model):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Classification report for VGG16\n",
        "print(\"\\nClassification Report for VGG16\")\n",
        "print_classification_report(vgg16)\n",
        "\n",
        "# Classification report for ResNet18\n",
        "print(\"\\nClassification Report for ResNet18\")\n",
        "print_classification_report(resnet18)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RjTjRJ5kgxQ",
        "outputId": "2549aef1-44be-4272-e681-7db7613cdae8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for VGG16\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         apple       0.98      0.94      0.96        62\n",
            "  baked potato       0.67      0.89      0.76        65\n",
            "        burger       0.85      0.85      0.85        67\n",
            "        coffee       0.93      0.93      0.93        42\n",
            "         curry       0.81      0.87      0.84        30\n",
            "         donut       0.94      0.86      0.90        76\n",
            "        durian       1.00      0.67      0.80         3\n",
            "   egg ballado       0.73      0.80      0.76        10\n",
            "  french fries       0.90      0.79      0.84        68\n",
            " fried chicken       0.78      0.82      0.80        66\n",
            "    fried rice       0.70      0.58      0.64        12\n",
            "     gado gado       0.70      0.78      0.74        65\n",
            "        grapes       0.90      0.69      0.78        13\n",
            "       hot dog       0.81      0.77      0.79        70\n",
            "     ice cream       0.50      1.00      0.67         3\n",
            "         kebab       1.00      0.60      0.75        15\n",
            "     meatballs       0.77      0.85      0.81        65\n",
            " mineral water       1.00      0.95      0.97        19\n",
            "        noodle       0.85      0.94      0.89        65\n",
            "          nuts       0.93      1.00      0.97        14\n",
            "      omelette       0.54      0.70      0.61        10\n",
            "        orange       0.97      0.98      0.98        65\n",
            "         pizza       0.89      0.82      0.85        67\n",
            "      porridge       0.52      0.65      0.58        17\n",
            "prawn crackers       1.00      0.60      0.75        15\n",
            "       rendang       0.88      0.68      0.77        65\n",
            "      sandwich       0.89      0.75      0.81        67\n",
            "         satay       0.93      0.91      0.92        68\n",
            "          soto       0.88      0.64      0.74        11\n",
            "          taco       0.60      0.72      0.66        72\n",
            "\n",
            "      accuracy                           0.83      1287\n",
            "     macro avg       0.83      0.80      0.80      1287\n",
            "  weighted avg       0.84      0.83      0.83      1287\n",
            "\n",
            "\n",
            "Classification Report for ResNet18\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         apple       0.97      0.94      0.95        62\n",
            "  baked potato       0.79      0.83      0.81        65\n",
            "        burger       0.90      0.79      0.84        67\n",
            "        coffee       0.91      0.95      0.93        42\n",
            "         curry       0.81      0.83      0.82        30\n",
            "         donut       0.94      0.80      0.87        76\n",
            "        durian       1.00      0.67      0.80         3\n",
            "   egg ballado       0.67      0.80      0.73        10\n",
            "  french fries       0.83      0.87      0.85        68\n",
            " fried chicken       0.84      0.88      0.86        66\n",
            "    fried rice       0.73      0.67      0.70        12\n",
            "     gado gado       0.79      0.75      0.77        65\n",
            "        grapes       0.80      0.62      0.70        13\n",
            "       hot dog       0.62      0.81      0.70        70\n",
            "     ice cream       0.30      1.00      0.46         3\n",
            "         kebab       0.69      0.73      0.71        15\n",
            "     meatballs       0.77      0.92      0.84        65\n",
            " mineral water       0.90      0.95      0.92        19\n",
            "        noodle       0.88      0.92      0.90        65\n",
            "          nuts       0.93      1.00      0.97        14\n",
            "      omelette       0.86      0.60      0.71        10\n",
            "        orange       0.94      0.95      0.95        65\n",
            "         pizza       0.79      0.85      0.82        67\n",
            "      porridge       0.69      0.53      0.60        17\n",
            "prawn crackers       1.00      0.60      0.75        15\n",
            "       rendang       0.84      0.75      0.80        65\n",
            "      sandwich       0.86      0.85      0.86        67\n",
            "         satay       0.91      0.94      0.93        68\n",
            "          soto       0.62      0.73      0.67        11\n",
            "          taco       0.90      0.62      0.74        72\n",
            "\n",
            "      accuracy                           0.83      1287\n",
            "     macro avg       0.82      0.81      0.80      1287\n",
            "  weighted avg       0.84      0.83      0.83      1287\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}